{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf79614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time\n",
    "from flask import Flask, render_template, Response, redirect\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "mixer.init()\n",
    "sound = mixer.Sound('alarm.wav')\n",
    "\n",
    "face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_righteye_2splits.xml')\n",
    "\n",
    "model = load_model('models/cnncat2.h5')\n",
    "path = os.getcwd()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "\n",
    "camera = None\n",
    "display_video = False\n",
    "\n",
    "sound_playing = False\n",
    "\n",
    "def fuzzy_sound(s):\n",
    "    score = ctrl.Antecedent(np.arange(6, 31, 1), 'score')\n",
    "\n",
    "    volume = ctrl.Consequent(np.arange(0, 1.5, 0.1), 'volume')\n",
    "\n",
    "    score['low'] = fuzz.trimf(score.universe, [6, 6, 15])\n",
    "    score['medium'] = fuzz.trimf(score.universe, [10, 15, 20])\n",
    "    score['high'] = fuzz.trimf(score.universe, [15, 30, 30])\n",
    "\n",
    "    volume['low'] = fuzz.trimf(volume.universe, [0, 0, 0.7])\n",
    "    volume['medium'] = fuzz.trimf(volume.universe, [0, 0.7, 1.4])\n",
    "    volume['high'] = fuzz.trimf(volume.universe, [0.7, 1.4, 1.4])\n",
    "\n",
    "    rule1 = ctrl.Rule(score['low'], volume['low'])\n",
    "    rule2 = ctrl.Rule(score['medium'], volume['medium'])\n",
    "    rule3 = ctrl.Rule(score['high'], volume['high'])\n",
    "\n",
    "    volume_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])\n",
    "    volume_sim = ctrl.ControlSystemSimulation(volume_ctrl)\n",
    "\n",
    "    volume_sim.input['score'] = s\n",
    "\n",
    "    volume_sim.compute()\n",
    "\n",
    "    return volume_sim.output['volume']\n",
    "\n",
    "def generate_frames():\n",
    "    global camera, sound, sound_playing, display_video\n",
    "    mixer.init()\n",
    "    score = 0\n",
    "    rpred = [99]\n",
    "    lpred = [99]\n",
    "    thicc = 2\n",
    "    while True:\n",
    "        success, frame = camera.read()\n",
    "        if not success:\n",
    "            break\n",
    "        else:\n",
    "            height,width = frame.shape[:2] \n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "            faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "            left_eye = leye.detectMultiScale(gray)\n",
    "            right_eye =  reye.detectMultiScale(gray)\n",
    "            \n",
    "            cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED)\n",
    "            \n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 2)\n",
    "\n",
    "                for (x,y,w,h) in right_eye:\n",
    "                    r_eye=frame[y:y+h,x:x+w]\n",
    "                    r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "                    r_eye = cv2.resize(r_eye,(24,24))\n",
    "                    r_eye= r_eye/255\n",
    "                    r_eye=  r_eye.reshape(24,24,-1)\n",
    "                    r_eye = np.expand_dims(r_eye,axis=0)\n",
    "                    rpred = model.predict(r_eye)\n",
    "                    rpred = np.argmax(rpred, axis=1)\n",
    "                    break\n",
    "\n",
    "                for (x,y,w,h) in left_eye:\n",
    "                    l_eye=frame[y:y+h,x:x+w]\n",
    "                    l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n",
    "                    l_eye = cv2.resize(l_eye,(24,24))\n",
    "                    l_eye= l_eye/255\n",
    "                    l_eye=l_eye.reshape(24,24,-1)\n",
    "                    l_eye = np.expand_dims(l_eye,axis=0)\n",
    "                    lpred = model.predict(l_eye)\n",
    "                    lpred = np.argmax(lpred, axis=1)\n",
    "                    break\n",
    "\n",
    "                break\n",
    "            \n",
    "            if(rpred[0]==0 and lpred[0]==0):\n",
    "                score=score+1\n",
    "                cv2.putText(frame,\"Closed\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "            else:\n",
    "                if(score > 0):\n",
    "                    score=score-1\n",
    "                cv2.putText(frame,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(frame,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "            if(score>6):\n",
    "                #person is feeling sleepy so we beep the alarm\n",
    "                cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "                volume = fuzzy_sound(score)\n",
    "                volume = round(volume, 2)\n",
    "                sound.set_volume(volume)\n",
    "                if not sound_playing:\n",
    "                    try:\n",
    "                        sound.play(loops=-1)\n",
    "                        sound_playing = True\n",
    "                    except:  # isplaying = False\n",
    "                        pass\n",
    "\n",
    "                if(thicc<16):\n",
    "                    thicc = thicc+2\n",
    "                else:\n",
    "                    if thicc>2:\n",
    "                        thicc = thicc-2\n",
    "                cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc)\n",
    "            else:\n",
    "                sound.stop()\n",
    "                sound_playing = False\n",
    "            \n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            \n",
    "        yield(b'--frame\\r\\n'\n",
    "                 b'Content-Type: image/jpeg\\r\\n\\r\\n'+frame+b'\\r\\n')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html', display_video=display_video)\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/start')\n",
    "def start():\n",
    "    global camera, display_video, sound\n",
    "    if camera is None:\n",
    "        camera = cv2.VideoCapture(0)\n",
    "        display_video = True\n",
    "    return redirect('/')\n",
    "\n",
    "@app.route('/stop')\n",
    "def stop():\n",
    "    global camera, display_video, sound, sound_playing\n",
    "    if camera is not None:\n",
    "        camera.release()\n",
    "        camera = None\n",
    "        display_video = False\n",
    "        mixer.quit()\n",
    "        sound_playing = False\n",
    "    return redirect('/')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e770d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-fuzzy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
